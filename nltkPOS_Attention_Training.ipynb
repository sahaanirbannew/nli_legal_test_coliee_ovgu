{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nltkPOS_Attention_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahaanirbannew/nli_legal_test_coliee_ovgu/blob/master/nltkPOS_Attention_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OvAjONUju26",
        "colab_type": "code",
        "outputId": "2e4a23d6-99c9-4f64-b039-bf73a930e4ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install pyspellchecker"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.29.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (47.1.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdt1R4oU0yAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7d956918-eeb3-42a4-a76e-8940a53ca170"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb5jVdRPgbEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "os.chdir('/content/drive/My Drive/COLIEE/Code/nli_coliee')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWiN5I7Xhajy",
        "colab_type": "code",
        "outputId": "3a2adc1f-7175-44f1-8acb-ef40360c6447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "import os\n",
        "import h5py\n",
        "import datetime\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "import nltk \n",
        "nltk.download('punkt')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import data_parser_for_POS as dp\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T_OaRJdjSLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PREPROCESSED_TRAIN_SET = \"preprocessed_training_set.json\"\n",
        "PREPROCESSED_REDUCED_TRAIN_SET = \"preprocessed_reduced_training_set.json\"\n",
        "PREPROCESSED_VALIDATION_SET = \"preprocessed_validation_set.json\"\n",
        "SAVE_MODEL_TO = \"models/nltkPOS/attention/\"\n",
        "SAVE_STATES_TO = \"states/nltkPOS/attention/states.hdf5\"\n",
        "SAVE_SCORES_TO = \"attention_scores/attention_scores_baseline.pkl\"\n",
        "SAVE_LOGS_TO = \"tensorBoardLogs/nltkPOS/attention/\"\n",
        "TRAINING_LOG = \"logs/nltkPOS/attention/training_performance_log.txt\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-hNTi3NkE_g",
        "colab_type": "code",
        "outputId": "e5a42495-c3bf-4062-8a9a-8446cdb9bd94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "\n",
        "CUSTOM_VALIDATION = False\n",
        "\n",
        "if not CUSTOM_VALIDATION:\n",
        "    X_train, y_train_labels = dp.get_data(PREPROCESSED_TRAIN_SET)\n",
        "    y_train = to_categorical(y_train_labels)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=5, stratify=y_train)\n",
        "else:\n",
        "    X_train, y_train_labels = dp.get_data(PREPROCESSED_REDUCED_TRAIN_SET)\n",
        "    y_train = to_categorical(y_train_labels)\n",
        "\n",
        "    # get manually set validation set\n",
        "    X_val, y_val_labels = dp.get_data(PREPROCESSED_VALIDATION_SET)\n",
        "    y_val = to_categorical(y_val_labels)\n",
        "\n",
        "    # Shuffle stratify split training set to get some random instances for validation set\n",
        "    X_train, X_val_random, y_train, y_val_random = train_test_split(X_train, y_train, test_size=0.1, random_state=10, stratify=y_train)\n",
        "    # best split seed values: 10\n",
        "    # bad splits: 58, 14, 94, 31, 24, 4, 95, 59\n",
        "\n",
        "    # append random instances with custom modelled validation set\n",
        "    y_val = np.concatenate((y_val, y_val_random))\n",
        "    X_val = np.concatenate((X_val, X_val_random))\n",
        "\n",
        "    del y_train_labels, y_val_labels, y_val_random, X_val_random\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/COLIEE/Code/nli_coliee/data_parser_for_POS.py:82: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  padded_matrix[slices] = matrix[slices]\n",
            "/content/drive/My Drive/COLIEE/Code/nli_coliee/data_parser_for_POS.py:83: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  padded_tags[slices] = tag[slices]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owtzWeMz0SXU",
        "colab_type": "code",
        "outputId": "1081d255-41b7-4443-d2c3-3ab0b41aaf8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "\n",
        "RAW_TEST_DATA = \"dataset/TestData_en.xml\"           # set file location to raw test xml\n",
        "LABELS_FILE = \"dataset/test_labels.txt\"             # set file location to test labels\n",
        "\n",
        "if os.path.exists('preprocessed_test_set.json'):\n",
        "    PREPROCESSED_TEST_SET = \"preprocessed_test_set.json\"            # Load json dump of test set, uncomment/comment this line \n",
        "    print('\\nPreprocessed test set loaded.')\n",
        "else:\n",
        "    PREPROCESSED_TEST_SET = pre.get_data(RAW_TEST_DATA, \"TEST\")     # Run preprocessing of test_set\n",
        "    with open('preprocessed_test_set.json', 'w') as fp:             \n",
        "        json.dump(PREPROCESSED_TEST_SET, fp)                        # Dump the preprocessed json file\n",
        "        \n",
        "    print('\\nPreprocessing of Test Set Complete!')\n",
        "    print('File {} saved to {}'.format('preprocessed_test_set.json',os.getcwd()))\n",
        "\n",
        "X_test = dp.get_data(PREPROCESSED_TEST_SET, 'TEST')                 # Parse and get X_test data\n",
        "print('\\nTest set parsing complete.')\n",
        "\n",
        "y_test = []                                                         \n",
        "with open(LABELS_FILE, \"r\", errors='ignore') as test_labels:        # Read labels from text file\n",
        "    for line in test_labels:\n",
        "        y_test.append(line.split(' ')[1])\n",
        "\n",
        "y_test = to_categorical(y_test)                                     # Categorize labels into binary format\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Preprocessed test set loaded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/COLIEE/Code/nli_coliee/data_parser_for_POS.py:82: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  padded_matrix[slices] = matrix[slices]\n",
            "/content/drive/My Drive/COLIEE/Code/nli_coliee/data_parser_for_POS.py:83: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  padded_tags[slices] = tag[slices]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set parsing complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YH19afxkPDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Parameters\n",
        "learning_rate = 0.000001\n",
        "num_input = X_train.shape[2]            # dimension of each sentence \n",
        "timesteps = X_train.shape[1]            # timesteps\n",
        "num_hidden = {1: 128, 2: 64}            # dictionary that defines number of neurons per layer \n",
        "num_classes = 2                         # total number of classes\n",
        "num_layers = 1                          # desired number of LSTM layers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nay7dW6alehT",
        "colab_type": "code",
        "outputId": "d722a566-e98e-45b8-b789-9dfad8383818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "# Clears the default graph stack and resets the global default graph. The default graph is a property of the current thread.\n",
        "# Once a graph is created, all placeholders, variables and any elements are actually part of the current thread.\n",
        "# If we need to re-execute any of the tensorflow related code again, you need to reset the graph to its default state.\n",
        "tf.compat.v1.reset_default_graph() \n",
        "\n",
        "# Declare placeholders for input and labels that is required for tensor graph\n",
        "X = tf.compat.v1.placeholder(\"float\", [None, timesteps, num_input])\n",
        "y = tf.compat.v1.placeholder(\"float\", [None, num_classes])\n",
        "\n",
        "# initializer = tf.random_normal_initializer(stddev=0.1)\n",
        "initializer = tf.contrib.layers.xavier_initializer()\n",
        "\n",
        "fc_weights = {\n",
        "        'out' : tf.Variable(initializer(([2*num_hidden[1], num_classes])), name='w_out')      # output weights for applying softmax\n",
        "        }\n",
        "\n",
        "fc_biases = {\n",
        "        'out' : tf.Variable(tf.zeros([num_classes]), name='b_out')                # output bias\n",
        "        }\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
        "weight_decay = tf.placeholder(tf.float32, name='weight_decay')\n",
        "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(fc_weights['out']))\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nykVON8xmDCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BiRNN(x, weights, bias):\n",
        "    '''\n",
        "        BiRNN: Defines the architecture of LSTM network for training\n",
        "        Args: \n",
        "                x:          premise_hypothesis pair\n",
        "                weights:    weights required to apply relu activation function over hidden layer and softmax activation over output layer \n",
        "                bias:       bias corresponding to the weights.\n",
        "        \n",
        "        Returns:\n",
        "            1. muladd() applied over last outputs with corresponding weights and bias\n",
        "            2. concatenated forward and backward cell states\n",
        "            3. whole rnn output\n",
        "    '''\n",
        "    x = tf.unstack(x, timesteps, 1)\n",
        "    output = x   \n",
        "    \n",
        "    for i in range(num_layers):\n",
        "        \n",
        "        lstm_fw_cell = rnn.BasicLSTMCell(num_hidden[i+1], forget_bias=1.0 , activation=tf.nn.leaky_relu )          # define forward lstm cell with hidden cells\n",
        "        lstm_fw_cell = rnn.DropoutWrapper(lstm_fw_cell, output_keep_prob=keep_prob)       # define dropout over hidden forward lstm cell\n",
        "        lstm_bw_cell = rnn.BasicLSTMCell(num_hidden[i+1], forget_bias=1.0 , activation=tf.nn.leaky_relu)          # define backward lstm cell with hidden cells\n",
        "        lstm_bw_cell = rnn.DropoutWrapper(lstm_bw_cell,  output_keep_prob=keep_prob)      # define dropout over hidden backward lstm cell\n",
        " \n",
        "        with tf.compat.v1.variable_scope('lstm'+str(i)):\n",
        "            try:\n",
        "                output, state_fw, state_bw = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, output, dtype=tf.float32)\n",
        "            except Exception: # Old TensorFlow version only returns outputs not states\n",
        "                output = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, output, dtype=tf.float32)\n",
        "            \n",
        "            #Venky: concatinating the forward  and the backward cell states of the Rnn cell\n",
        "            if i == num_layers-1: #last layer\n",
        "                _ = tf.concat([state_fw.c, state_bw.c], axis=1, name='bidirectional_concat_c')\n",
        "                _ = tf.concat([state_fw.h, state_bw.h], axis=1, name='bidirectional_concat_h')\n",
        "            \n",
        "            # Venky: rnn cell output  --> currently this is not used for LSTMVis\n",
        "            outputs = tf.unstack(output, timesteps, 0)\n",
        "            outputs = tf.transpose(outputs, perm=[1, 0, 2]) \n",
        "    \n",
        "    return tf.add(tf.matmul(output[-1], weights['out']), bias['out']), outputs\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWq7HEa6mn89",
        "colab_type": "code",
        "outputId": "82e04d97-ad31-4a75-9789-bb834d0f9c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "with tf.name_scope(\"attention\"):\n",
        "\n",
        "    pre_logits , output  = BiRNN(X, fc_weights, fc_biases)\n",
        "    initializer = tf.random_normal_initializer(stddev=0.1) # he_initializer , xavier_initialiser\n",
        "    print(output.shape)\n",
        "    hidden_states = output.shape[2]\n",
        "    print(hidden_states)\n",
        "    \n",
        "    w_hidden = tf.get_variable(name=\"w_hidden\", shape=[hidden_states, timesteps ], initializer=initializer)\n",
        "    b_hidden = tf.get_variable(name=\"b_hidden\", shape=[timesteps], initializer=initializer)\n",
        "    w_output = tf.get_variable(name=\"w_output\", shape=[timesteps], initializer=initializer)  \n",
        "    # adding a one output node in the output layer creates a separate column vector for all the attention weights over which the softmax is applied, that created the problem previously\n",
        "\n",
        "    score = tf.tanh(tf.tensordot( output, w_hidden, axes=1) + b_hidden)\n",
        "    # Linear transformation by mulitiplying the weights and the rnn outputs and applying a non linear activtion over this output\n",
        "\n",
        "    attention = tf.tensordot(score , w_output, axes=1, name='attention')\n",
        "\n",
        "    attention_score = tf.nn.softmax(attention , name='attention_score') \n",
        "\n",
        "    attention_out = tf.reduce_sum( output * tf.expand_dims(attention_score, -1), 1)\n",
        "    \n",
        "    print(attention_score.shape)\n",
        "    print(attention_out.shape)\n",
        "\n",
        "tf.compat.v1.summary.histogram(\"attention_score\", attention_score)  # write attention score values to tensorboard summary (histogram visualization)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-36-80c8f567603e>:19: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-36-80c8f567603e>:26: static_bidirectional_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:1610: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "(?, 283, 256)\n",
            "256\n",
            "(?, 283)\n",
            "(?, 256)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'attention_score:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm-ja9K0m6HZ",
        "colab_type": "code",
        "outputId": "c0c4665e-ecd4-45f5-9c52-72959b107137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "with tf.name_scope(\"output\"):\n",
        "    logits = tf.contrib.slim.fully_connected(attention_out, 2, activation_fn=None)\n",
        "    prediction = tf.nn.softmax(logits, name='prediction')   # applies softmax over BiRNN output to calculate predicted values\n",
        "tf.compat.v1.summary.histogram(\"prediction\", prediction)    # write predicted values to tensorboard summary (histogram visualization)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'prediction:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qMsOZUcnEO9",
        "colab_type": "code",
        "outputId": "851393e6-96ce-48cd-84b9-b73517f84798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "with tf.name_scope(\"loss\"):\n",
        "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))      # calculate loss \n",
        "    tf.compat.v1.summary.scalar('loss_op', loss_op)                                                 # write loss values to tensorboard summary \n",
        "                                                                                                    # (histogram visualization)\n",
        "    \n",
        "    reg_losses = tf.compat.v1.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)                              # apply regularizer over output weights\n",
        "    loss_op = loss_op + weight_decay * tf.add_n(reg_losses)                                                   # add regularization term with loss.\n",
        "    \n",
        "    #     optimizer = tf.compat.v1.train.RMSPropOptimizer(learning_rate)\n",
        "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate)                                     # apply Adam Optimizer for loss optimization\n",
        "    gvs = optimizer.compute_gradients(loss_op)                                                      # fetch gradient values\n",
        "#     capped_gvs = [(tf.clip_by_value(grad, -0.1, 0.1), var) for grad, var in gvs]                    # clip each gradient value within the limit\n",
        "    \n",
        "    train_op = optimizer.apply_gradients(gvs)                                                       # applied clipped gradients\n",
        "    #     train_op = optimizer.minimize(loss_op)\n",
        "   \n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-39-54d01f522f34>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzBLvfAsoT_0",
        "colab_type": "code",
        "outputId": "014afa1a-7cc0-4d75-ca04-ef92eac45dba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with tf.name_scope(\"accuracy\"):\n",
        "    correct_predictions = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))                       # obtain correct predictions on comparison with actual labels\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, 'float'), name=\"accuracy\")               # mean of correct predictions\n",
        "tf.compat.v1.summary.scalar('accuracy', accuracy)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG3aewWzTca_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_LSTM_states(states_inter, state_val, SAVE_STATES_TO):\n",
        "    '''\n",
        "    Description:    Saves LSTM states to disk\n",
        "    Input:          1. states_inter: list of states from batch inputs. Eg: If number_of_batches = 4, len(states_inter) = 4\n",
        "                    2. state_val: list of states from validation input\n",
        "                    3. SAVE_STATES_TO: location where the states file have to saved to\n",
        "    Output:         HDF5 file of lstm states saved to SAVE_STATES_TO location\n",
        "    '''\n",
        "    final_states = []\n",
        "    states_inter = np.vstack(states_inter)\n",
        "    final_states.append(states_inter)                       # append training_states to final_states\n",
        "    final_states.append(np.array(state_val))                # append validation_states to final_states\n",
        "    val_1 = final_states[0][0]\n",
        "    for k in range(len(final_states)):\n",
        "        for i in range(0,len(final_states[k])):\n",
        "            temp = final_states[k][i]\n",
        "            val_1 = np.concatenate((val_1,temp),axis=0)\n",
        "    print('\\nSaving LSTM states...')\n",
        "    with h5py.File(SAVE_STATES_TO, 'w') as hf:\n",
        "        hf.create_dataset(\"d1\",  data= val_1)\n",
        "    print('LSTM states saved to {}'.format(SAVE_STATES_TO))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE88--7wTfwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion(y_test, pred):\n",
        "    labels = [0, 1]\n",
        "    cm = confusion_matrix(y_test, pred, labels)\n",
        "    precision = cm[1][1] / (cm[1][1] + cm[0][1])\n",
        "    recall = cm[1][1] / (cm[1][1] + cm[1][0])\n",
        "    print('Confusion Matrix')\n",
        "    print(cm)\n",
        "    print('Precision: {}'.format(precision))\n",
        "    print('Recall: {}'.format(recall))\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(cm, cmap='summer')\n",
        "\n",
        "    for (i, j), z in np.ndenumerate(cm):\n",
        "        ax.text(j, i, '{:0.1f}'.format(z), ha='center', va='center')\n",
        "\n",
        "    plt.title('Confusion matrix of Baseline')\n",
        "    fig.colorbar(cax)\n",
        "    ax.set_xticklabels([''] + labels)\n",
        "    ax.set_yticklabels([''] + labels)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rig2pfeaoU-s",
        "colab_type": "code",
        "outputId": "46bf3dcd-5b03-4bed-a9a8-baacaf2cc80c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%matplotlib inline \n",
        "def run_train(session, train_x, train_y):\n",
        "    '''\n",
        "    Description:    Trains the BiLSTM model with given training set in batches and returns final training results and states\n",
        "    Input:          1. session: Tensorflow session\n",
        "                    2. train_x: training set of padded premise_hypothesis sequences\n",
        "                    3. train_y: Two column binary labels that corresponds to the train_x\n",
        "    Output:         List of training accuracy and loss results, List of final training and validation states\n",
        "    '''\n",
        "    print(\"\\nStart training\")\n",
        "    ###################################################\n",
        "    # initialization of local variables and lists:\n",
        "    acc_results = []\n",
        "    loss_results = []\n",
        "    train_counter = 0\n",
        "    validation_counter = 0\n",
        "\n",
        "    training_steps = 10  # epochs\n",
        "    batch_size = 128        # batch size\n",
        "    display_step = 10       # displays\n",
        "\n",
        "    #for early stopping :\n",
        "    best_loss_val=1000000   # initializing best validation loss to a higher value.\n",
        "    best_train_acc = 0      # best training accuracy\n",
        "    last_improvement=0      # a counter which keeps the record of since when (timesteps/iterations) last improvement was seen\n",
        "    patience= 10            # the number of epochs without improvement you allow before training should be aborted\n",
        "    # since the values are updated every 10th iteration, the stopping limit becomes: (patience * 10)\n",
        "\n",
        "    costs = []              # validation costs history\n",
        "    costs_inter=[]          # intermediate validation costs. These values are only used as a log to keep track of the costs.\n",
        "    best_loss_observed_epoch = 0\n",
        "\n",
        "    ###################################################\n",
        "\n",
        "    session.run(tf.compat.v1.global_variables_initializer())                        # initialize all variables using session\n",
        "    for epoch in range(1, training_steps + 1):                                      # training iterations\n",
        "        train_x, train_y = shuffle(train_x, train_y)\n",
        "        inner_split = train_x.shape[0] // batch_size                                # creating batches\n",
        "        states_inter = []\n",
        "        scores_inter = []\n",
        "        attention_scores = []                                                       # list to append final training and validation attention scores\n",
        "\n",
        "        for i in range(inner_split + 1):\n",
        "            batch_x = train_x[i*batch_size:(i+1)*batch_size]                        # generating batches of X_train\n",
        "            batch_y = train_y[i*batch_size:(i+1)*batch_size]                        # generating batches of y_train\n",
        "            session.run(train_op, feed_dict={X: batch_x, y: batch_y, keep_prob :0.5, weight_decay:1e-01})\n",
        "\n",
        "            if epoch == 1 or epoch % display_step == 0:                             # print and save necessary information about training only at an interval of 'display_step' number of steps to reduce computational complexity\n",
        "\n",
        "                state_train , attention_train  = session.run([output,attention_score], feed_dict={X: batch_x, y: batch_y, keep_prob :0.5, weight_decay:1e-01})     # extract states for each batch-wise training inputs\n",
        "                # print(state_train.shape)\n",
        "                states_inter.append(np.array(state_train))\n",
        "                # print(len(states_inter))\n",
        "                scores_inter.append(np.array(attention_train))\n",
        "                # print(len(states_inter))\n",
        "                if i == inner_split:                                                # last batch split of the selected epoch\n",
        "                    summary, loss_train, acc_train = session.run([merged, loss_op, accuracy], feed_dict={X: batch_x, y: batch_y, keep_prob :0.5, weight_decay:1e-01})\n",
        "                    train_writer.add_summary(summary, train_counter)\n",
        "\n",
        "                    summary, loss_val, acc_val, pred_val ,state_val ,attention_val = session.run([merged, loss_op, accuracy, prediction, output , attention_score ], feed_dict={X: X_val, y: y_val , keep_prob :1.0, weight_decay:0.0})\n",
        "                    validation_writer.add_summary(summary, validation_counter)\n",
        "                    train_counter+=display_step\n",
        "                    validation_counter+=display_step\n",
        "\n",
        "                    if math.isnan(loss_val):\n",
        "                        sys.exit(\"\\n!!! Explosion of gradients !!! \\nTerminating program!\")\n",
        "\n",
        "                    print(\"Epoch {}, Batch Split {}\".format(epoch, i+1) + \", Minibatch Loss= \" + \\\n",
        "                      \"{:.4f}\".format(loss_train) + \", Minibatch Training Accuracy= \" + \\\n",
        "                      \"{:.3f}\".format(acc_train))\n",
        "                    print(\" Validation Loss = {:.4f}\".format(loss_val) + \", Validation Accuracy= {:.3f}\".format(acc_val))\n",
        "\n",
        "                    acc_results.append(acc_train)\n",
        "                    loss_results.append(loss_train)\n",
        "\n",
        "                    #...... BEGIN EARLY STOPPING EVALUATION ......\n",
        "\n",
        "                    # CONDITION:\n",
        "                    # 1. If validation loss has not decreased since 20 steps\n",
        "                    #   1.1. If the average of last 20 iterations are less than 0.72\n",
        "\n",
        "                    costs_inter.append(loss_val)            # append validation loss to costs_inter\n",
        "\n",
        "                    if loss_val < best_loss_val:            # if improved validation loss found\n",
        "                        best_loss_val = loss_val            # set current validation loss to best_loss_val\n",
        "                        best_train_acc = acc_train          # set current training accuracy to best_train_acc\n",
        "                        best_val_acc = acc_val              # set current validation accuracy to acc_val\n",
        "                        costs +=costs_inter                 # append intermediate cost history to costs\n",
        "                        last_improvement = 0                # reset last_improvement\n",
        "                        costs_inter= []                     # reset costs_inter\n",
        "                        best_loss_observed_epoch = epoch\n",
        "                    else:\n",
        "                        last_improvement +=1                # else, increment last_improvement\n",
        "\n",
        "                    if last_improvement > patience:                         # if no improvement seen over 'patience' number of steps\n",
        "                        print('\\n Validation Confusion Matrix: ')\n",
        "                        plot_confusion(np.argmax(y_val, axis=1), np.argmax(pred_val, axis=1))\n",
        "                        print(\"\\nNo improvement found during the last {} iterations\".format(patience))\n",
        "                        print('Avg validation loss over this period: ', sum(costs_inter)/len(costs_inter))\n",
        "\n",
        "                        _ = saver.save(session, SAVE_MODEL_TO+\"m_{}_{}.ckpt\".format(acc_train, acc_val), global_step=epoch)\n",
        "\n",
        "                        print('Recording training and validation states at cost of early-stopping')\n",
        "                        save_LSTM_states(states_inter, state_val, SAVE_STATES_TO+'-final.hdf5')\n",
        "\n",
        "                        scores_inter = np.vstack(scores_inter)\n",
        "                        attention_scores.append(scores_inter)\n",
        "                        attention_scores.append(np.array(attention_val))\n",
        "\n",
        "                        return acc_results, loss_results, attention_scores\n",
        "\n",
        "\n",
        "                    elif epoch % 100 == 0:                                                   # else, save checkpoint and reset costs_inter and last_improvement\n",
        "                        print('\\n Validation Confusion Matrix: ')\n",
        "                        plot_confusion(np.argmax(y_val, axis=1), np.argmax(pred_val, axis=1))\n",
        "                        print('\\nSaving Checkpoint...')\n",
        "                        _ = saver.save(session, SAVE_MODEL_TO+\"m_{}_{}.ckpt\".format(acc_train, acc_val), global_step=epoch)\n",
        "                        print('<<<Model Checkpoint saved>>>')\n",
        "                        print('<<<State Checkpoint saved>>>')\n",
        "                        save_LSTM_states(states_inter, state_val, SAVE_STATES_TO+'-'+str(epoch)+'.hdf5')\n",
        "\n",
        "                        print('Continuing Training...\\n')\n",
        "\n",
        "\n",
        "                    #...... END EARLY STOPPING EVALUATION ......\n",
        "\n",
        "                    if epoch == training_steps:                                 # do not change this intendation to make sure this line run only once and not for each split of the epoch!\n",
        "\n",
        "                        print('\\n Validation Confusion Matrix: ')\n",
        "                        plot_confusion(np.argmax(y_val, axis=1), np.argmax(pred_val, axis=1))\n",
        "\n",
        "                        _ = saver.save(session, SAVE_MODEL_TO+\"m_{}_{}.ckpt\".format(acc_train, acc_val), global_step=epoch)                         # save model to local\n",
        "\n",
        "                        print('Recording final training and validation states')\n",
        "                        save_LSTM_states(states_inter, state_val, SAVE_STATES_TO+'-final.hdf5')\n",
        "\n",
        "                        scores_inter = np.vstack(scores_inter)\n",
        "                        attention_scores.append(scores_inter)\n",
        "                        attention_scores.append(np.array(attention_val))\n",
        "\n",
        "                        print('\\nBest result: Training acc = {}, Validation acc = {} observed at {}'.format(best_train_acc, best_val_acc, best_loss_observed_epoch)) # the best result seen before 'no improvements'\n",
        "\n",
        "    print(attention_scores[0].shape, attention_scores[1].shape)\n",
        "    print(\"Total attention list \" + str(len(attention_scores)))\n",
        "    return acc_results, loss_results, attention_scores\n",
        "\n",
        "\n",
        "\n",
        "saver = tf.compat.v1.train.Saver()\n",
        "saver = tf.compat.v1.train.Saver()\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    # Log for tensorboard visualization\n",
        "    logdir = os.path.join(SAVE_LOGS_TO, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    merged = tf.compat.v1.summary.merge_all()\n",
        "    train_writer = tf.compat.v1.summary.FileWriter(logdir + '/train', sess.graph)\n",
        "    validation_writer = tf.compat.v1.summary.FileWriter(logdir + '/validation')\n",
        "\n",
        "    start_time = datetime.datetime.now()\n",
        "    print('-'*50)\n",
        "    print('Session started at: {}'.format(start_time))\n",
        "    acc_results, loss_results,  attention_scores = run_train(sess, X_train, y_train)\n",
        "    print('Training performance: Accuracy {}, Loss {}'.format(acc_results[-1], loss_results[-1]))\n",
        "    end_time = datetime.datetime.now()\n",
        "    print('Total Execution time: {} minutes'.format(end_time.minute - start_time.minute))\n",
        "\n",
        "    f = open(SAVE_SCORES_TO,'wb')\n",
        "    pickle.dump(attention_scores,f)\n",
        "\n",
        "    print('Attention scores saved to {}\\{}'.format(os.getcwd(), SAVE_SCORES_TO))\n",
        "\n",
        "    print(\"Testing on Test Dataset\")\n",
        "\n",
        "    loss_test, acc_test , pred_test = sess.run([loss_op, accuracy , prediction], feed_dict={X: X_test, y: y_test, keep_prob :1.0, weight_decay:0.0})\n",
        "\n",
        "    print('\\nTest Loss = {}, Test Accuracy = {}'.format(loss_test, acc_test))\n",
        "    plot_confusion(np.argmax(y_test, axis=1), np.argmax(pred_test, axis=1))\n",
        "\n",
        "    sess.close()\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Session started at: 2020-06-09 20:50:52.766175\n",
            "\n",
            "Start training\n",
            "(128, 283, 256)\n",
            "1\n",
            "1\n",
            "(128, 283, 256)\n",
            "2\n",
            "2\n",
            "(128, 283, 256)\n",
            "3\n",
            "3\n",
            "(117, 283, 256)\n",
            "4\n",
            "4\n",
            "Epoch 1, Batch Split 4, Minibatch Loss= 0.9017, Minibatch Training Accuracy= 0.521\n",
            " Validation Loss = 0.6930, Validation Accuracy= 0.524\n",
            "(128, 283, 256)\n",
            "1\n",
            "1\n",
            "(128, 283, 256)\n",
            "2\n",
            "2\n",
            "(128, 283, 256)\n",
            "3\n",
            "3\n",
            "(117, 283, 256)\n",
            "4\n",
            "4\n",
            "Epoch 10, Batch Split 4, Minibatch Loss= 0.9007, Minibatch Training Accuracy= 0.513\n",
            " Validation Loss = 0.6928, Validation Accuracy= 0.524\n",
            "\n",
            " Validation Confusion Matrix: \n",
            "Confusion Matrix\n",
            "[[62  2]\n",
            " [58  4]]\n",
            "Precision: 0.6666666666666666\n",
            "Recall: 0.06451612903225806\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Recording final training and validation states\n",
            "\n",
            "Saving LSTM states...\n",
            "LSTM states saved to states/nltkPOS/attention/states.hdf5-final.hdf5\n",
            "\n",
            "Best result: Training acc = 0.5128205418586731, Validation acc = 0.523809552192688 observed at 10\n",
            "(501, 283) (126, 283)\n",
            "Total attention list 2\n",
            "Training performance: Accuracy 0.5128205418586731, Loss 0.9007412791252136\n",
            "Total Execution time: 2 minutes\n",
            "Attention scores saved to /content/drive/My Drive/COLIEE/Code/nli_coliee\\attention_scores/attention_scores_baseline.pkl\n",
            "Testing on Test Dataset\n",
            "\n",
            "Test Loss = 0.6920742392539978, Test Accuracy = 0.5204081535339355\n",
            "Confusion Matrix\n",
            "[[49  2]\n",
            " [45  2]]\n",
            "Precision: 0.5\n",
            "Recall: 0.0425531914893617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_awQw_dxKiD",
        "colab_type": "code",
        "outputId": "76d90f3d-2f7a-476e-e963-45fa544fe422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tensorBoardLogs/nltkPOS/attention/"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}