{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sim_neg_Attention_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahaanirbannew/nli_legal_test_coliee_ovgu/blob/master/Sim_neg_Attention_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZLAfeuj3eLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "92e427df-4232-4c2a-c38c-95c309ea1204"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OvAjONUju26",
        "colab_type": "code",
        "outputId": "1a51ffac-1883-4d10-9775-03d148239cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install pyspellchecker"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.29.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (47.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb5jVdRPgbEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "os.chdir('/content/drive/My Drive/COLIEE/Code/nli_coliee')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWiN5I7Xhajy",
        "colab_type": "code",
        "outputId": "ff3aa7d7-f974-4675-9e44-4dab805f74c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "import os\n",
        "import h5py\n",
        "import datetime\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import data_parser_for_simneg as dp\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "from keras.utils.np_utils import to_categorical\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Here\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "--------------------------------------------------\n",
            "Check if pre-trained Word2vec model trained on Google News corpus exists in disk\n",
            "\n",
            "Model not found!\n",
            "Here!!!\n",
            "\tCheck if the binary of Google News Dataset present in disk\n",
            "\tBinary of Google News Dataset found. Now loading...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tThe Google News Dataset is loaded. Model initialising...\n",
            "Model loaded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T_OaRJdjSLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PREPROCESSED_TRAIN_SET = \"preprocessed_training_set.json\"\n",
        "PREPROCESSED_REDUCED_TRAIN_SET = \"preprocessed_reduced_training_set.json\"\n",
        "PREPROCESSED_VALIDATION_SET = \"preprocessed_validation_set.json\"\n",
        "SAVE_MODEL_TO = \"models/sim_neg/attention/\"\n",
        "SAVE_STATES_TO = \"states/sim_neg/attention/states.hdf5\"\n",
        "SAVE_SCORES_TO = \"attention_scores/attention_scores_baseline.pkl\"\n",
        "SAVE_LOGS_TO = \"tensorBoardLogs/sim_neg/attention/\"\n",
        "TRAINING_LOG = \"logs/sim_neg/attention/training_performance_log.txt\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-hNTi3NkE_g",
        "colab_type": "code",
        "outputId": "e0825e3e-cec3-416f-9a20-07042b392ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "\n",
        "CUSTOM_VALIDATION = False\n",
        "\n",
        "if not CUSTOM_VALIDATION:\n",
        "    X_train, y_train_labels = dp.get_data(PREPROCESSED_TRAIN_SET)\n",
        "    y_train = to_categorical(y_train_labels)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=5, stratify=y_train)\n",
        "else:\n",
        "    X_train, y_train_labels = dp.get_data(PREPROCESSED_REDUCED_TRAIN_SET)\n",
        "    y_train = to_categorical(y_train_labels)\n",
        "\n",
        "    # get manually set validation set\n",
        "    X_val, y_val_labels = dp.get_data(PREPROCESSED_VALIDATION_SET)\n",
        "    y_val = to_categorical(y_val_labels)\n",
        "\n",
        "    # Shuffle stratify split training set to get some random instances for validation set\n",
        "    X_train, X_val_random, y_train, y_val_random = train_test_split(X_train, y_train, test_size=0.1, random_state=10, stratify=y_train)\n",
        "    # best split seed values: 10\n",
        "    # bad splits: 58, 14, 94, 31, 24, 4, 95, 59\n",
        "\n",
        "    # append random instances with custom modelled validation set\n",
        "    y_val = np.concatenate((y_val, y_val_random))\n",
        "    X_val = np.concatenate((X_val, X_val_random))\n",
        "\n",
        "    del y_train_labels, y_val_labels, y_val_random, X_val_random\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/COLIEE/Code/nli_coliee/data_parser_for_simneg.py:66: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  padded_matrix[slices] = matrix[slices]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owtzWeMz0SXU",
        "colab_type": "code",
        "outputId": "25270b0d-38dd-4062-9b8f-a4e51e345eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "\n",
        "RAW_TEST_DATA = \"dataset/TestData_en.xml\"           # set file location to raw test xml\n",
        "LABELS_FILE = \"dataset/test_labels.txt\"             # set file location to test labels\n",
        "\n",
        "if os.path.exists('preprocessed_test_set.json'):\n",
        "    PREPROCESSED_TEST_SET = \"preprocessed_test_set.json\"            # Load json dump of test set, uncomment/comment this line \n",
        "    print('\\nPreprocessed test set loaded.')\n",
        "else:\n",
        "    PREPROCESSED_TEST_SET = pre.get_data(RAW_TEST_DATA, \"TEST\")     # Run preprocessing of test_set\n",
        "    with open('preprocessed_test_set.json', 'w') as fp:             \n",
        "        json.dump(PREPROCESSED_TEST_SET, fp)                        # Dump the preprocessed json file\n",
        "        \n",
        "    print('\\nPreprocessing of Test Set Complete!')\n",
        "    print('File {} saved to {}'.format('preprocessed_test_set.json',os.getcwd()))\n",
        "\n",
        "X_test = dp.get_data(PREPROCESSED_TEST_SET, 'TEST')                 # Parse and get X_test data\n",
        "print('\\nTest set parsing complete.')\n",
        "\n",
        "y_test = []                                                         \n",
        "with open(LABELS_FILE, \"r\", errors='ignore') as test_labels:        # Read labels from text file\n",
        "    for line in test_labels:\n",
        "        y_test.append(line.split(' ')[1])\n",
        "\n",
        "y_test = to_categorical(y_test)                                     # Categorize labels into binary format\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Preprocessed test set loaded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/COLIEE/Code/nli_coliee/data_parser_for_simneg.py:66: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  padded_matrix[slices] = matrix[slices]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set parsing complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YH19afxkPDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Parameters\n",
        "learning_rate = 0.000001\n",
        "num_input = X_train.shape[2]            # dimension of each sentence \n",
        "timesteps = X_train.shape[1]            # timesteps\n",
        "num_hidden = {1: 128, 2: 64}            # dictionary that defines number of neurons per layer \n",
        "num_classes = 2                         # total number of classes\n",
        "num_layers = 1                          # desired number of LSTM layers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nay7dW6alehT",
        "colab_type": "code",
        "outputId": "5204f845-2ffc-4c94-f42c-9e5f208db210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "# Clears the default graph stack and resets the global default graph. The default graph is a property of the current thread.\n",
        "# Once a graph is created, all placeholders, variables and any elements are actually part of the current thread.\n",
        "# If we need to re-execute any of the tensorflow related code again, you need to reset the graph to its default state.\n",
        "tf.compat.v1.reset_default_graph() \n",
        "\n",
        "# Declare placeholders for input and labels that is required for tensor graph\n",
        "X = tf.compat.v1.placeholder(\"float\", [None, timesteps, num_input])\n",
        "y = tf.compat.v1.placeholder(\"float\", [None, num_classes])\n",
        "\n",
        "# initializer = tf.random_normal_initializer(stddev=0.1)\n",
        "initializer = tf.contrib.layers.xavier_initializer()\n",
        "\n",
        "fc_weights = {\n",
        "        'out' : tf.Variable(initializer(([2*num_hidden[1], num_classes])), name='w_out')      # output weights for applying softmax\n",
        "        }\n",
        "\n",
        "fc_biases = {\n",
        "        'out' : tf.Variable(tf.zeros([num_classes]), name='b_out')                # output bias\n",
        "        }\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
        "weight_decay = tf.placeholder(tf.float32, name='weight_decay')\n",
        "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(fc_weights['out']))\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nykVON8xmDCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BiRNN(x, weights, bias):\n",
        "    '''\n",
        "        BiRNN: Defines the architecture of LSTM network for training\n",
        "        Args: \n",
        "                x:          premise_hypothesis pair\n",
        "                weights:    weights required to apply relu activation function over hidden layer and softmax activation over output layer \n",
        "                bias:       bias corresponding to the weights.\n",
        "        \n",
        "        Returns:\n",
        "            1. muladd() applied over last outputs with corresponding weights and bias\n",
        "            2. concatenated forward and backward cell states\n",
        "            3. whole rnn output\n",
        "    '''\n",
        "    x = tf.unstack(x, timesteps, 1)\n",
        "    output = x   \n",
        "    \n",
        "    for i in range(num_layers):\n",
        "        \n",
        "        lstm_fw_cell = rnn.BasicLSTMCell(num_hidden[i+1], forget_bias=1.0 , activation=tf.nn.leaky_relu )          # define forward lstm cell with hidden cells\n",
        "        lstm_fw_cell = rnn.DropoutWrapper(lstm_fw_cell, output_keep_prob=keep_prob)       # define dropout over hidden forward lstm cell\n",
        "        lstm_bw_cell = rnn.BasicLSTMCell(num_hidden[i+1], forget_bias=1.0 , activation=tf.nn.leaky_relu)          # define backward lstm cell with hidden cells\n",
        "        lstm_bw_cell = rnn.DropoutWrapper(lstm_bw_cell,  output_keep_prob=keep_prob)      # define dropout over hidden backward lstm cell\n",
        " \n",
        "        with tf.compat.v1.variable_scope('lstm'+str(i)):\n",
        "            try:\n",
        "                output, state_fw, state_bw = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, output, dtype=tf.float32)\n",
        "            except Exception: # Old TensorFlow version only returns outputs not states\n",
        "                output = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, output, dtype=tf.float32)\n",
        "            \n",
        "            #Venky: concatinating the forward  and the backward cell states of the Rnn cell\n",
        "            if i == num_layers-1: #last layer\n",
        "                _ = tf.concat([state_fw.c, state_bw.c], axis=1, name='bidirectional_concat_c')\n",
        "                _ = tf.concat([state_fw.h, state_bw.h], axis=1, name='bidirectional_concat_h')\n",
        "            \n",
        "            # Venky: rnn cell output  --> currently this is not used for LSTMVis\n",
        "            outputs = tf.unstack(output, timesteps, 0)\n",
        "            outputs = tf.transpose(outputs, perm=[1, 0, 2]) \n",
        "    \n",
        "    return tf.add(tf.matmul(output[-1], weights['out']), bias['out']), outputs\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWq7HEa6mn89",
        "colab_type": "code",
        "outputId": "a27b4783-7e53-4d00-9dc8-83830e48bcb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "with tf.name_scope(\"attention\"):\n",
        "\n",
        "    pre_logits , output  = BiRNN(X, fc_weights, fc_biases)\n",
        "    initializer = tf.random_normal_initializer(stddev=0.1) # he_initializer , xavier_initialiser\n",
        "    print(output.shape)\n",
        "    hidden_states = output.shape[2]\n",
        "    print(hidden_states)\n",
        "    \n",
        "    w_hidden = tf.get_variable(name=\"w_hidden\", shape=[hidden_states, timesteps ], initializer=initializer)\n",
        "    b_hidden = tf.get_variable(name=\"b_hidden\", shape=[timesteps], initializer=initializer)\n",
        "    w_output = tf.get_variable(name=\"w_output\", shape=[timesteps], initializer=initializer)  \n",
        "    # adding a one output node in the output layer creates a separate column vector for all the attention weights over which the softmax is applied, that created the problem previously\n",
        "\n",
        "    score = tf.tanh(tf.tensordot( output, w_hidden, axes=1) + b_hidden)\n",
        "    # Linear transformation by mulitiplying the weights and the rnn outputs and applying a non linear activtion over this output\n",
        "\n",
        "    attention = tf.tensordot(score , w_output, axes=1, name='attention')\n",
        "\n",
        "    attention_score = tf.nn.softmax(attention , name='attention_score') \n",
        "\n",
        "    attention_out = tf.reduce_sum( output * tf.expand_dims(attention_score, -1), 1)\n",
        "    \n",
        "    print(attention_score.shape)\n",
        "    print(attention_out.shape)\n",
        "\n",
        "tf.compat.v1.summary.histogram(\"attention_score\", attention_score)  # write attention score values to tensorboard summary (histogram visualization)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-80c8f567603e>:19: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-15-80c8f567603e>:26: static_bidirectional_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:1610: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "(?, 284, 256)\n",
            "256\n",
            "(?, 284)\n",
            "(?, 256)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'attention_score:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm-ja9K0m6HZ",
        "colab_type": "code",
        "outputId": "be361fae-6f64-46be-9d2d-0bc5fbcdc6f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "with tf.name_scope(\"output\"):\n",
        "    logits = tf.contrib.slim.fully_connected(attention_out, 2, activation_fn=None)\n",
        "    prediction = tf.nn.softmax(logits, name='prediction')   # applies softmax over BiRNN output to calculate predicted values\n",
        "tf.compat.v1.summary.histogram(\"prediction\", prediction)    # write predicted values to tensorboard summary (histogram visualization)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'prediction:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qMsOZUcnEO9",
        "colab_type": "code",
        "outputId": "8e7430d6-d175-4515-e7c6-3b47de7537cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "with tf.name_scope(\"loss\"):\n",
        "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))      # calculate loss \n",
        "    tf.compat.v1.summary.scalar('loss_op', loss_op)                                                 # write loss values to tensorboard summary \n",
        "                                                                                                    # (histogram visualization)\n",
        "    \n",
        "    reg_losses = tf.compat.v1.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)                              # apply regularizer over output weights\n",
        "    loss_op = loss_op + weight_decay * tf.add_n(reg_losses)                                                   # add regularization term with loss.\n",
        "    \n",
        "    #     optimizer = tf.compat.v1.train.RMSPropOptimizer(learning_rate)\n",
        "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate)                                     # apply Adam Optimizer for loss optimization\n",
        "    gvs = optimizer.compute_gradients(loss_op)                                                      # fetch gradient values\n",
        "#     capped_gvs = [(tf.clip_by_value(grad, -0.1, 0.1), var) for grad, var in gvs]                    # clip each gradient value within the limit\n",
        "    \n",
        "    train_op = optimizer.apply_gradients(gvs)                                                       # applied clipped gradients\n",
        "    #     train_op = optimizer.minimize(loss_op)\n",
        "   \n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-54d01f522f34>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzBLvfAsoT_0",
        "colab_type": "code",
        "outputId": "b55d9d07-b72b-4048-fdda-b1b7243d5080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with tf.name_scope(\"accuracy\"):\n",
        "    correct_predictions = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))                       # obtain correct predictions on comparison with actual labels\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, 'float'), name=\"accuracy\")               # mean of correct predictions\n",
        "tf.compat.v1.summary.scalar('accuracy', accuracy)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG3aewWzTca_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_LSTM_states(states_inter, state_val, SAVE_STATES_TO):\n",
        "    '''\n",
        "    Description:    Saves LSTM states to disk\n",
        "    Input:          1. states_inter: list of states from batch inputs. Eg: If number_of_batches = 4, len(states_inter) = 4\n",
        "                    2. state_val: list of states from validation input\n",
        "                    3. SAVE_STATES_TO: location where the states file have to saved to\n",
        "    Output:         HDF5 file of lstm states saved to SAVE_STATES_TO location\n",
        "    '''\n",
        "    final_states = []\n",
        "    states_inter = np.vstack(states_inter)\n",
        "    final_states.append(states_inter)                       # append training_states to final_states\n",
        "    final_states.append(np.array(state_val))                # append validation_states to final_states\n",
        "    val_1 = final_states[0][0]\n",
        "    for k in range(len(final_states)):\n",
        "        for i in range(0,len(final_states[k])):\n",
        "            temp = final_states[k][i]\n",
        "            val_1 = np.concatenate((val_1,temp),axis=0)\n",
        "    print('\\nSaving LSTM states...')\n",
        "    with h5py.File(SAVE_STATES_TO, 'w') as hf:\n",
        "        hf.create_dataset(\"d1\",  data= val_1)\n",
        "    print('LSTM states saved to {}'.format(SAVE_STATES_TO))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE88--7wTfwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion(y_test, pred):\n",
        "    labels = [0, 1]\n",
        "    cm = confusion_matrix(y_test, pred, labels)\n",
        "    precision = cm[1][1] / (cm[1][1] + cm[0][1])\n",
        "    recall = cm[1][1] / (cm[1][1] + cm[1][0])\n",
        "    print('Confusion Matrix')\n",
        "    print(cm)\n",
        "    print('Precision: {}'.format(precision))\n",
        "    print('Recall: {}'.format(recall))\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(cm, cmap='summer')\n",
        "\n",
        "    for (i, j), z in np.ndenumerate(cm):\n",
        "        ax.text(j, i, '{:0.1f}'.format(z), ha='center', va='center')\n",
        "\n",
        "    plt.title('Confusion matrix of Baseline')\n",
        "    fig.colorbar(cax)\n",
        "    ax.set_xticklabels([''] + labels)\n",
        "    ax.set_yticklabels([''] + labels)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rig2pfeaoU-s",
        "colab_type": "code",
        "outputId": "912b19bd-4695-4dcd-fe2b-22243183b4ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%matplotlib inline \n",
        "def run_train(session, train_x, train_y):\n",
        "    '''\n",
        "    Description:    Trains the BiLSTM model with given training set in batches and returns final training results and states\n",
        "    Input:          1. session: Tensorflow session\n",
        "                    2. train_x: training set of padded premise_hypothesis sequences\n",
        "                    3. train_y: Two column binary labels that corresponds to the train_x\n",
        "    Output:         List of training accuracy and loss results, List of final training and validation states\n",
        "    '''\n",
        "    print(\"\\nStart training\")\n",
        "    ###################################################\n",
        "    # initialization of local variables and lists:\n",
        "    acc_results = []\n",
        "    loss_results = []\n",
        "    train_counter = 0\n",
        "    validation_counter = 0\n",
        "\n",
        "    training_steps = 10  # epochs\n",
        "    batch_size = 128        # batch size\n",
        "    display_step = 10       # displays\n",
        "\n",
        "    #for early stopping :\n",
        "    best_loss_val=1000000   # initializing best validation loss to a higher value.\n",
        "    best_train_acc = 0      # best training accuracy\n",
        "    last_improvement=0      # a counter which keeps the record of since when (timesteps/iterations) last improvement was seen\n",
        "    patience= 10            # the number of epochs without improvement you allow before training should be aborted\n",
        "    # since the values are updated every 10th iteration, the stopping limit becomes: (patience * 10)\n",
        "\n",
        "    costs = []              # validation costs history\n",
        "    costs_inter=[]          # intermediate validation costs. These values are only used as a log to keep track of the costs.\n",
        "    best_loss_observed_epoch = 0\n",
        "\n",
        "    ###################################################\n",
        "\n",
        "    session.run(tf.compat.v1.global_variables_initializer())                        # initialize all variables using session\n",
        "    for epoch in range(1, training_steps + 1):                                      # training iterations\n",
        "        train_x, train_y = shuffle(train_x, train_y)\n",
        "        inner_split = train_x.shape[0] // batch_size                                # creating batches\n",
        "        states_inter = []\n",
        "        scores_inter = []\n",
        "        attention_scores = []                                                       # list to append final training and validation attention scores\n",
        "\n",
        "        for i in range(inner_split + 1):\n",
        "            batch_x = train_x[i*batch_size:(i+1)*batch_size]                        # generating batches of X_train\n",
        "            batch_y = train_y[i*batch_size:(i+1)*batch_size]                        # generating batches of y_train\n",
        "            session.run(train_op, feed_dict={X: batch_x, y: batch_y, keep_prob :0.5, weight_decay:1e-01})\n",
        "\n",
        "            if epoch == 1 or epoch % display_step == 0:                             # print and save necessary information about training only at an interval of 'display_step' number of steps to reduce computational complexity\n",
        "\n",
        "                state_train , attention_train  = session.run([output,attention_score], feed_dict={X: batch_x, y: batch_y, keep_prob :0.5, weight_decay:1e-01})     # extract states for each batch-wise training inputs\n",
        "                # print(state_train.shape)\n",
        "                states_inter.append(np.array(state_train))\n",
        "                # print(len(states_inter))\n",
        "                scores_inter.append(np.array(attention_train))\n",
        "                # print(len(states_inter))\n",
        "                if i == inner_split:                                                # last batch split of the selected epoch\n",
        "                    summary, loss_train, acc_train = session.run([merged, loss_op, accuracy], feed_dict={X: batch_x, y: batch_y, keep_prob :0.5, weight_decay:1e-01})\n",
        "                    train_writer.add_summary(summary, train_counter)\n",
        "\n",
        "                    summary, loss_val, acc_val, pred_val ,state_val ,attention_val = session.run([merged, loss_op, accuracy, prediction, output , attention_score ], feed_dict={X: X_val, y: y_val , keep_prob :1.0, weight_decay:0.0})\n",
        "                    validation_writer.add_summary(summary, validation_counter)\n",
        "                    train_counter+=display_step\n",
        "                    validation_counter+=display_step\n",
        "\n",
        "                    if math.isnan(loss_val):\n",
        "                        sys.exit(\"\\n!!! Explosion of gradients !!! \\nTerminating program!\")\n",
        "\n",
        "                    print(\"Epoch {}, Batch Split {}\".format(epoch, i+1) + \", Minibatch Loss= \" + \\\n",
        "                      \"{:.4f}\".format(loss_train) + \", Minibatch Training Accuracy= \" + \\\n",
        "                      \"{:.3f}\".format(acc_train))\n",
        "                    print(\" Validation Loss = {:.4f}\".format(loss_val) + \", Validation Accuracy= {:.3f}\".format(acc_val))\n",
        "\n",
        "                    acc_results.append(acc_train)\n",
        "                    loss_results.append(loss_train)\n",
        "\n",
        "                    #...... BEGIN EARLY STOPPING EVALUATION ......\n",
        "\n",
        "                    # CONDITION:\n",
        "                    # 1. If validation loss has not decreased since 20 steps\n",
        "                    #   1.1. If the average of last 20 iterations are less than 0.72\n",
        "\n",
        "                    costs_inter.append(loss_val)            # append validation loss to costs_inter\n",
        "\n",
        "                    if loss_val < best_loss_val:            # if improved validation loss found\n",
        "                        best_loss_val = loss_val            # set current validation loss to best_loss_val\n",
        "                        best_train_acc = acc_train          # set current training accuracy to best_train_acc\n",
        "                        best_val_acc = acc_val              # set current validation accuracy to acc_val\n",
        "                        costs +=costs_inter                 # append intermediate cost history to costs\n",
        "                        last_improvement = 0                # reset last_improvement\n",
        "                        costs_inter= []                     # reset costs_inter\n",
        "                        best_loss_observed_epoch = epoch\n",
        "                    else:\n",
        "                        last_improvement +=1                # else, increment last_improvement\n",
        "\n",
        "                    if last_improvement > patience:                         # if no improvement seen over 'patience' number of steps\n",
        "                        print('\\n Validation Confusion Matrix: ')\n",
        "                        plot_confusion(np.argmax(y_val, axis=1), np.argmax(pred_val, axis=1))\n",
        "                        print(\"\\nNo improvement found during the last {} iterations\".format(patience))\n",
        "                        print('Avg validation loss over this period: ', sum(costs_inter)/len(costs_inter))\n",
        "\n",
        "                        _ = saver.save(session, SAVE_MODEL_TO+\"m_{}_{}.ckpt\".format(acc_train, acc_val), global_step=epoch)\n",
        "\n",
        "                        print('Recording training and validation states at cost of early-stopping')\n",
        "                        save_LSTM_states(states_inter, state_val, SAVE_STATES_TO+'-final.hdf5')\n",
        "\n",
        "                        scores_inter = np.vstack(scores_inter)\n",
        "                        attention_scores.append(scores_inter)\n",
        "                        attention_scores.append(np.array(attention_val))\n",
        "\n",
        "                        return acc_results, loss_results, attention_scores\n",
        "\n",
        "\n",
        "                    elif epoch % 100 == 0:                                                   # else, save checkpoint and reset costs_inter and last_improvement\n",
        "                        print('\\n Validation Confusion Matrix: ')\n",
        "                        plot_confusion(np.argmax(y_val, axis=1), np.argmax(pred_val, axis=1))\n",
        "                        print('\\nSaving Checkpoint...')\n",
        "                        _ = saver.save(session, SAVE_MODEL_TO+\"m_{}_{}.ckpt\".format(acc_train, acc_val), global_step=epoch)\n",
        "                        print('<<<Model Checkpoint saved>>>')\n",
        "                        print('<<<State Checkpoint saved>>>')\n",
        "                        save_LSTM_states(states_inter, state_val, SAVE_STATES_TO+'-'+str(epoch)+'.hdf5')\n",
        "\n",
        "                        print('Continuing Training...\\n')\n",
        "\n",
        "\n",
        "                    #...... END EARLY STOPPING EVALUATION ......\n",
        "\n",
        "                    if epoch == training_steps:                                 # do not change this intendation to make sure this line run only once and not for each split of the epoch!\n",
        "\n",
        "                        print('\\n Validation Confusion Matrix: ')\n",
        "                        plot_confusion(np.argmax(y_val, axis=1), np.argmax(pred_val, axis=1))\n",
        "\n",
        "                        _ = saver.save(session, SAVE_MODEL_TO+\"m_{}_{}.ckpt\".format(acc_train, acc_val), global_step=epoch)                         # save model to local\n",
        "\n",
        "                        print('Recording final training and validation states')\n",
        "                        save_LSTM_states(states_inter, state_val, SAVE_STATES_TO+'-final.hdf5')\n",
        "\n",
        "                        scores_inter = np.vstack(scores_inter)\n",
        "                        attention_scores.append(scores_inter)\n",
        "                        attention_scores.append(np.array(attention_val))\n",
        "\n",
        "                        print('\\nBest result: Training acc = {}, Validation acc = {} observed at {}'.format(best_train_acc, best_val_acc, best_loss_observed_epoch)) # the best result seen before 'no improvements'\n",
        "\n",
        "    print(attention_scores[0].shape, attention_scores[1].shape)\n",
        "    print(\"Total attention list \" + str(len(attention_scores)))\n",
        "    return acc_results, loss_results, attention_scores\n",
        "\n",
        "\n",
        "\n",
        "saver = tf.compat.v1.train.Saver()\n",
        "saver = tf.compat.v1.train.Saver()\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    # Log for tensorboard visualization\n",
        "    logdir = os.path.join(SAVE_LOGS_TO, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    merged = tf.compat.v1.summary.merge_all()\n",
        "    train_writer = tf.compat.v1.summary.FileWriter(logdir + '/train', sess.graph)\n",
        "    validation_writer = tf.compat.v1.summary.FileWriter(logdir + '/validation')\n",
        "\n",
        "    start_time = datetime.datetime.now()\n",
        "    print('-'*50)\n",
        "    print('Session started at: {}'.format(start_time))\n",
        "    acc_results, loss_results,  attention_scores = run_train(sess, X_train, y_train)\n",
        "    print('Training performance: Accuracy {}, Loss {}'.format(acc_results[-1], loss_results[-1]))\n",
        "    end_time = datetime.datetime.now()\n",
        "    print('Total Execution time: {} minutes'.format(end_time.minute - start_time.minute))\n",
        "\n",
        "    f = open(SAVE_SCORES_TO,'wb')\n",
        "    pickle.dump(attention_scores,f)\n",
        "\n",
        "    print('Attention scores saved to {}\\{}'.format(os.getcwd(), SAVE_SCORES_TO))\n",
        "\n",
        "    print(\"Testing on Test Dataset\")\n",
        "\n",
        "    loss_test, acc_test , pred_test = sess.run([loss_op, accuracy , prediction], feed_dict={X: X_test, y: y_test, keep_prob :1.0, weight_decay:0.0})\n",
        "\n",
        "    print('\\nTest Loss = {}, Test Accuracy = {}'.format(loss_test, acc_test))\n",
        "    plot_confusion(np.argmax(y_test, axis=1), np.argmax(pred_test, axis=1))\n",
        "\n",
        "    sess.close()\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Session started at: 2020-06-09 21:03:15.057889\n",
            "\n",
            "Start training\n",
            "(128, 284, 256)\n",
            "1\n",
            "1\n",
            "(128, 284, 256)\n",
            "2\n",
            "2\n",
            "(128, 284, 256)\n",
            "3\n",
            "3\n",
            "(117, 284, 256)\n",
            "4\n",
            "4\n",
            "Epoch 1, Batch Split 4, Minibatch Loss= 2.9249, Minibatch Training Accuracy= 0.444\n",
            " Validation Loss = 0.9567, Validation Accuracy= 0.516\n",
            "(128, 284, 256)\n",
            "1\n",
            "1\n",
            "(128, 284, 256)\n",
            "2\n",
            "2\n",
            "(128, 284, 256)\n",
            "3\n",
            "3\n",
            "(117, 284, 256)\n",
            "4\n",
            "4\n",
            "Epoch 10, Batch Split 4, Minibatch Loss= 2.6168, Minibatch Training Accuracy= 0.444\n",
            " Validation Loss = 1.4004, Validation Accuracy= 0.500\n",
            "\n",
            " Validation Confusion Matrix: \n",
            "Confusion Matrix\n",
            "[[ 1 63]\n",
            " [ 0 62]]\n",
            "Precision: 0.496\n",
            "Recall: 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Recording final training and validation states\n",
            "\n",
            "Saving LSTM states...\n",
            "LSTM states saved to states/sim_neg/attention/states.hdf5-final.hdf5\n",
            "\n",
            "Best result: Training acc = 0.4444444477558136, Validation acc = 0.5158730149269104 observed at 1\n",
            "(501, 284) (126, 284)\n",
            "Total attention list 2\n",
            "Training performance: Accuracy 0.4444444477558136, Loss 2.616809368133545\n",
            "Total Execution time: 2 minutes\n",
            "Attention scores saved to /content/drive/My Drive/COLIEE/Code/nli_coliee\\attention_scores/attention_scores_baseline.pkl\n",
            "Testing on Test Dataset\n",
            "\n",
            "Test Loss = 1.3400934934616089, Test Accuracy = 0.4897959232330322\n",
            "Confusion Matrix\n",
            "[[ 2 49]\n",
            " [ 1 46]]\n",
            "Precision: 0.4842105263157895\n",
            "Recall: 0.9787234042553191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_awQw_dxKiD",
        "colab_type": "code",
        "outputId": "945ca003-24b3-46b0-e905-30ef9d9b2ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tensorBoardLogs/sim_neg/attention/"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}